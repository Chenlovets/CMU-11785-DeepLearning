{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "cuda = torch.cuda.is_available()\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822154, 2300)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = torchvision.datasets.ImageFolder(root='train_data/medium', \n",
    "                                                       transform=torchvision.transforms.ToTensor())\n",
    "trainset.__len__(), len(trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 2300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalset = torchvision.datasets.ImageFolder(root='validation_classification/medium', \n",
    "                                                       transform=torchvision.transforms.ToTensor())\n",
    "evalset.__len__(), len(evalset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_args = dict(shuffle=True, batch_size=128,drop_last=False, num_workers=2,pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True,drop_last=False, batch_size=128)\n",
    "train_loader = DataLoader(trainset, **train_loader_args)\n",
    "\n",
    "eval_loader_args = dict(shuffle=True, batch_size=128,drop_last=False, num_workers=2,pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True,drop_last=False, batch_size=128)\n",
    "eval_loader = DataLoader(evalset, **eval_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut=[]\n",
    "            self.shortcut.append(nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False))\n",
    "            self.shortcut.append(nn.BatchNorm2d(out_channels))\n",
    "            self.shortcut = nn.Sequential(*self.shortcut)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        y = self.bn2(self.conv2(y)) \n",
    "        y += self.shortcut(x)\n",
    "        y = F.relu(y, inplace=True)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenterLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        feat_dim (int): feature dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, feat_dim, device=torch.device('cpu')):\n",
    "        super(CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).to(self.device))\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (batch_size).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "        distmat.addmm_(1, -2, x, self.centers.t())\n",
    "\n",
    "        classes = torch.arange(self.num_classes).long().to(self.device)\n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
    "\n",
    "        dist = []\n",
    "        for i in range(batch_size):\n",
    "            value = distmat[i][mask[i]]\n",
    "            value = value.clamp(min=1e-12, max=1e+12) # for numerical stability\n",
    "            dist.append(value)\n",
    "        dist = torch.cat(dist)\n",
    "        loss = dist.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, feat_dim=2):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.layers = []\n",
    "        \n",
    "        self.layers.append(nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, padding=1, stride=1, bias=False))\n",
    "        self.layers.append(nn.BatchNorm2d(128))\n",
    "        self.layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layers.append(IdentityBlock(in_channels=128, out_channels=128, stride=1))\n",
    "        self.layers.append(IdentityBlock(in_channels=128, out_channels=128, stride=1))\n",
    "       \n",
    "        self.layers.append(IdentityBlock(in_channels=128, out_channels=256, stride=2))\n",
    "        self.layers.append(IdentityBlock(in_channels=256, out_channels=256, stride=1))\n",
    "        \n",
    "        self.layers.append(IdentityBlock(in_channels=256, out_channels=512, stride=1))\n",
    "        self.layers.append(IdentityBlock(in_channels=512, out_channels=512, stride=1))\n",
    "        \n",
    "        self.layers.append(IdentityBlock(in_channels=512, out_channels=1024, stride=2))\n",
    "        self.layers.append(IdentityBlock(in_channels=1024, out_channels=1024, stride=1))\n",
    "\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.linear_label = nn.Linear(1024, 2300, bias=True)\n",
    "        \n",
    "        # For creating the embedding to be passed into the Center Loss criterion\n",
    "        self.linear_closs = nn.Linear(1024, feat_dim, bias=True)\n",
    "        self.relu_closs = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x, evalMode=False):\n",
    "        output = x\n",
    "        output = self.layers(output)\n",
    "\n",
    "        output = F.avg_pool2d(output, [output.size(2), output.size(3)], stride=1)\n",
    "        output = output.reshape(output.shape[0], output.shape[1])\n",
    "        \n",
    "        label_output = self.linear_label(output)\n",
    "        label_output = label_output/torch.norm(self.linear_label.weight, dim=1)\n",
    "        \n",
    "        # Create the feature embedding for the Center Loss\n",
    "        closs_output = self.linear_closs(output)\n",
    "        closs_output = self.relu_closs(closs_output)\n",
    "\n",
    "        return closs_output, label_output, output\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, test_loader, task='Classification'):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(numEpochs):\n",
    "        avg_loss = 0.0\n",
    "        for batch_num, (feats, labels) in enumerate(data_loader):\n",
    "            feats, labels = feats.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer_label.zero_grad()\n",
    "            optimizer_closs.zero_grad()\n",
    "            \n",
    "            feature, outputs, embedding = model(feats)\n",
    "\n",
    "            l_loss = criterion_label(outputs, labels.long())\n",
    "            c_loss = criterion_closs(feature, labels.long())\n",
    "            loss = l_loss + closs_weight * c_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer_label.step()\n",
    "            # by doing so, weight_cent would not impact on the learning of centers\n",
    "            for param in criterion_closs.parameters():\n",
    "                param.grad.data *= (1. / closs_weight)\n",
    "            optimizer_closs.step()\n",
    "\n",
    "            print('batch completed ' + str(batch_num / 822154 * 128 * 100) + '% ', end='\\r')\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            if batch_num % 100 == 99:\n",
    "                print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/100))\n",
    "                avg_loss = 0.0\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            del feats\n",
    "            del labels\n",
    "            del loss\n",
    "        \n",
    "        if task == 'Classification':\n",
    "            val_loss, val_acc = test_classify_closs(model, test_loader)\n",
    "            #train_loss, train_acc = test_classify_closs(model, data_loader)\n",
    "            print('Val Loss: {:.4f}\\tVal Accuracy: {:.4f}'.format(val_loss, val_acc))\n",
    "\n",
    "def test_classify_closs(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        feature, outputs, embedding = model(feats)\n",
    "        \n",
    "        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        \n",
    "        l_loss = criterion_label(outputs, labels.long())\n",
    "        c_loss = criterion_closs(feature, labels.long())\n",
    "        loss = l_loss + closs_weight * c_loss\n",
    "        \n",
    "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "        test_loss.extend([loss.item()]*feats.size()[0])\n",
    "        del feats\n",
    "        del labels\n",
    "\n",
    "    model.train()\n",
    "    return np.mean(test_loss), accuracy/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "numEpochs = 5\n",
    "closs_weight = 0.003\n",
    "num_feats = 3\n",
    "learningRate = 3e-4\n",
    "lr_cent = 0.5\n",
    "feat_dim = 2\n",
    "\n",
    "cnn=Network(feat_dim)\n",
    "cnn_dict = cnn.state_dict()\n",
    "pretrained = torch.load('resnetnet_best.pth')\n",
    "pretrained_dict = pretrained.state_dict()\n",
    "cnn_dict.update(pretrained_dict) \n",
    "cnn.load_state_dict(cnn_dict)\n",
    "\n",
    "criterion_label = nn.CrossEntropyLoss()\n",
    "criterion_closs = CenterLoss(2300, feat_dim, device)\n",
    "optimizer_label = torch.optim.Adam(cnn.parameters(),lr=learningRate)\n",
    "optimizer_closs = torch.optim.SGD(criterion_closs.parameters(), lr=lr_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.train()\n",
    "cnn.to(device)\n",
    "train(cnn, train_loader, eval_loader,task='verification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Images169392\n"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.file_list[index])\n",
    "        img = torchvision.transforms.ToTensor()(img)\n",
    "        return img\n",
    "\n",
    "img_sequence=[]\n",
    "\n",
    "def parse_data(datadir):\n",
    "    img_list = []\n",
    "    for root, directories, filenames in os.walk(datadir):\n",
    "        for filename in filenames:\n",
    "            #img_sequence.append(filename)\n",
    "            if filename.endswith('.jpg'):\n",
    "                filei = os.path.join(root,filename)\n",
    "                img_list.append(filei)\n",
    "                #img_list.append(filei[24:])\n",
    "\n",
    "    print('{}{}'.format('#Images', len(img_list)))\n",
    "    return img_list\n",
    "\n",
    "img_list = parse_data('test_verification/')\n",
    "\n",
    "testset = TestDataset(img_list)\n",
    "test_loader_args = dict(shuffle=False, batch_size=256, pin_memory=True, drop_last=False) \n",
    "test_loader = DataLoader(testset, **test_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, test_loader):\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    verification = torch.FloatTensor().to(device)\n",
    "\n",
    "    for batch_num, feats in enumerate(test_loader):\n",
    "        feats = feats.to(device)\n",
    "        outputs = model(feats)[2]\n",
    "        \n",
    "        verification = torch.cat((verification, outputs), dim=0)\n",
    "        \n",
    "    return verification\n",
    "\n",
    "embedding = verify(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings={}\n",
    "for index, i in enumerate(img_list):\n",
    "    embeddings[i[18:]]=embedding[index].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "trial=[]\n",
    "score=[]\n",
    "\n",
    "with open('test_trials_verification_student.txt') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for line in content:\n",
    "    trial.append(line.strip())\n",
    "    line=line.strip().split(' ')\n",
    "    embedding_1 = embeddings[line[0]].reshape(1,embeddings[line[0]].shape[0])\n",
    "    embedding_2 = embeddings[line[1]].reshape(1,embeddings[line[0]].shape[0])\n",
    "    similarity = cosine_similarity(embedding_1, embedding_2)\n",
    "    score.append(similarity[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = pd.DataFrame()\n",
    "result['trial'] = trial\n",
    "result['score'] = score\n",
    "result.to_csv('/home/ubuntu/zichenli_hw2_verification_3.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9223930009582997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "y_true=[]\n",
    "y_score=[]\n",
    "\n",
    "with open('validation_trials_verification.txt') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for line in content:\n",
    "    line=line.split(' ')\n",
    "    y_true.append(float(line[2]))\n",
    "\n",
    "with open('validation_verification.txt') as f:\n",
    "    content2 = f.readlines()\n",
    "\n",
    "for line in content2:\n",
    "    line=line.split(' ')\n",
    "    y_score.append(float(line[2]))\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_true, y_score)\n",
    "print (auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
